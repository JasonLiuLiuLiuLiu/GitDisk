# 我爱造轮子之定时沙漏

## 背景

闲的没事,自己写了个小网站,搭建在自己国外的VPS上,VPS内存极小(512M),而且还要跑点别的(你懂的),内存更紧张巴巴. 改造之前小网站用到了时髦的Redis,Rabbmitmq,Mysql,那时候学生主机内存富足,可到了这样的小内存VPS上,一切都变得水土不服,索性啥中间件都不要了,数据库也不要了.  
没了数据库,网站的数据从哪里来?存在哪里?  sqlite?持久化到文本?  
VPS可以被雷劈,可以掉海里,毕竟不是国内的服务器,可能哪天说不能访问就不能访问了,如果只是数据只是持久化在VPS的磁盘上,那不是叫我寝食难安?  
这时同事给我建议了万能的Github,谁说Github只能存代码,还能存女装大佬,当然也能存网站的数据.

于是我对网站架构进行了重新设计,如下.

![users](https://disk.iblogs.site/pic/iblogs.site/datasync.png)  

小网站数据不多,所有数据直接加载到内存中估计也就10M左右,另外一个定时任务把内存中的数据的列化成json同步到Github进行持久化.  

这时候,在我的眼里,Github已经不是Github了,而是一块延时略高的磁盘(其实延时也还好,国外的Github访问速度飞快).

既然把它视为一块磁盘,那么如果减少数据从内存到磁盘(Github)的同步开销呢?显然就是减少同步的频率,我起初是设计一小时同步一次,但是想到如果我的网站在这一小时内挂了数据还没来得及同步,那上次一同步到网站挂掉这个时间段内的数据不就没了吗?  
大家可能都能想到,一个可能的解决办法就是加大同步频率,比如说一分钟亦或是十分钟同步一次.  
其实这样也是有问题的,小网站一般都是无人问津,如果以较高的频率进行数据同步,可以说绝大多数甚至99.99%的数据同步都是没意义的同时还增大了数据的同步开销.  

我在决绝这个问题时,从局部性原理上找到了灵感.  

## 局部性原理

在揭开这个答案前,我们先来过一下CPU访问存储器时所遵守的局部性原理.  

局部性原理在是建立在这个金字塔上的,越靠近金字塔顶端,空间越小,但是读取数据越快;越靠近金字塔底端,空间越大,但访问速度也越慢.  
正式因为这样,所以每次自下而上的数据流空间大小应该是逐渐递减, 越往下数据交换的频率应该越低.  
所以为了提高CPU数据处理的效率,如何在恰当的时间取到恰当的数据是关键.  

![users](https://disk.iblogs.site/pic/iblogs.site/memory-hierarchy.png)  

### 空间局部性

如果一条数据被访问,那么与它临近的数据也可能要被用到. 比如数组,你访问了索引1上的数据,那么1附近的数据当然很有可能被访问,所以这个时候干脆把1附近的数据也往上加载一个层级.  

### 时间局部性

如果一条数据项正在被访问，那么在近期它很可能还会被再次访问,所以这个时候干脆就把它留在当前层级,先不急着回收了.    


而我所利用的,正是时间局部性,试想我们的数据我们的系统在日志的同步上也具有时间局部性,试想一下,像我这样并不热门的博客,基本没人访问,三十一旦访问了,即产生数据变更了,那是不是极有可能在短时间内残生二次数据变更呢?  

## Talk is cheap show me the code

看看代码

``` c#
public class BlogsTimer
{
    private static Stack<int> _upFunnel;
    private static Stack<int> _downFunnel;
    private static readonly List<Action> TimerEvents;
    private static bool _timerSwitch;
    private static readonly int Speed;
    private static Thread _timerThread;
    private static readonly object TimerLock;
    static BlogsTimer()
    {
        _upFunnel = new Stack<int>();
        _downFunnel = new Stack<int>();
        Speed = 1 * 1000;
        TimerEvents = new List<Action>();
        TimerLock = new object();
    }
    public static void Start(TimeSpan timeSpan)
    {
        lock (TimerLock)
        {
            _upFunnel.Clear();
            _downFunnel.Clear();
            for (var i = 0; i < timeSpan.TotalSeconds; i++)
            {
                _upFunnel.Push(i);
            }
        }
        _timerSwitch = true;
        _timerThread = new Thread(Consume);
        _timerThread.Start();
        LunchEvents();
    }
    public static void Stop()
    {
        _timerSwitch = false;
    }
    public static void Register(Action timeEvent)
    {
        TimerEvents.Add(timeEvent);
        timeEvent.Invoke();
    }
    public static void AccelerateTo(TimeSpan timeSpan)
    {
        var accelerateSeconds = timeSpan.TotalSeconds;
        lock (TimerLock)
        {
            if (_upFunnel.Count < accelerateSeconds)
                return;
            while (_upFunnel.Count > accelerateSeconds && _upFunnel.Count > 1)
            {
                _downFunnel.Push(_upFunnel.Pop());
            }
        }
    }
    private static void LunchEvents()
    {
        TimerEvents.ForEach(a => a.Invoke());
    }
    private static void Consume()
    {
        while (_timerSwitch)
        {
            lock (TimerLock)
            {
                if (_upFunnel.TryPop(out var item))
                {
                    _downFunnel.Push(item);
                }
                else
                {
                    LunchEvents();
                    var tempStack = _downFunnel;
                    _downFunnel = _upFunnel;
                    _upFunnel = tempStack;
                }
            }
            Thread.Sleep(Speed);
        }
    }
}

```